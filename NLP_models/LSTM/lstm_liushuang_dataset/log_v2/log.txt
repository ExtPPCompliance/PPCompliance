BiLSTMModel(
  (lstm): LSTM(100, 256, bidirectional=True)
  (attention_weights_layer): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU(inplace=True)
  )
  (liner): Linear(in_features=256, out_features=11, bias=True)
  (act_func): Softmax(dim=1)
)
Train Loss: 0.0017469682030597392, Train Acc: 0.8385534270522252
Test Loss: 0.1095295531766398, Test Acc: 0.8385052447552448
Train Loss: 0.0014922107461403321, Train Acc: 0.8432879306577318
Test Loss: 0.08539532085919714, Test Acc: 0.8526005244755245
Train Loss: 0.0010490605691881327, Train Acc: 0.874644912229587
Test Loss: 0.06758351591448267, Test Acc: 0.881993006993007
Train Loss: 0.000865640476782813, Train Acc: 0.8950396969917692
Test Loss: 0.06143196491146838, Test Acc: 0.8863636363636364
Train Loss: 0.0007055129243429433, Train Acc: 0.9103357855634059
Test Loss: 0.0610344317461644, Test Acc: 0.8898601398601399
Train Loss: 0.0005591376295396135, Train Acc: 0.9284361570398426
Test Loss: 0.06471172187451299, Test Acc: 0.8898601398601399
Train Loss: 0.0004339014467697731, Train Acc: 0.9432587952509287
Test Loss: 0.07174008004888371, Test Acc: 0.8802447552447552
Train Loss: 0.0003397636419320238, Train Acc: 0.9560419549857965
Test Loss: 0.08061166958219104, Test Acc: 0.883631993006993
Train Loss: 0.00026459301711755497, Train Acc: 0.9652560273872824
Test Loss: 0.08510754269163509, Test Acc: 0.8737980769230769
Train Loss: 0.00022311901099895183, Train Acc: 0.9715929783669605
Test Loss: 0.09266328789502173, Test Acc: 0.881993006993007
Train Loss: 0.0002070035699640853, Train Acc: 0.9735960375846747
Test Loss: 0.09592778565218815, Test Acc: 0.8830856643356644
Train Loss: 0.00016393955735633133, Train Acc: 0.9782212834146696
Test Loss: 0.09782406858370438, Test Acc: 0.887347027972028
Train Loss: 0.0001635300807487353, Train Acc: 0.9789132493262437
Test Loss: 0.10013605985087115, Test Acc: 0.885708041958042
Train Loss: 0.00014084938370361363, Train Acc: 0.9810619855779736
Test Loss: 0.104083004296868, Test Acc: 0.8730332167832168
Train Loss: 0.00015737985365561806, Train Acc: 0.9786947337752203
Test Loss: 0.09670327186350014, Test Acc: 0.8769667832167832
Train Loss: 0.00011900788340556358, Train Acc: 0.9825915944351373
Test Loss: 0.1030902183008986, Test Acc: 0.8815559440559441
Train Loss: 0.00011434006928291921, Train Acc: 0.9833199796052152
Test Loss: 0.10266020584043924, Test Acc: 0.8816652097902098
Train Loss: 0.00011429056884458887, Train Acc: 0.9836113336732464
Test Loss: 0.10625121112053211, Test Acc: 0.8775131118881119
Train Loss: 0.00010411535045632036, Train Acc: 0.9838298492242697
Test Loss: 0.11111179745098303, Test Acc: 0.8825393356643356
Train Loss: 0.00010179152050513898, Train Acc: 0.9843761381018282
Test Loss: 0.11465523251286754, Test Acc: 0.8809003496503497
Train Loss: 0.00011194001648443436, Train Acc: 0.983065044795688
Test Loss: 0.10729548461422637, Test Acc: 0.8834134615384616
Train Loss: 0.00010335946338590579, Train Acc: 0.9847767499453711
Test Loss: 0.113740303345233, Test Acc: 0.8742351398601399
Train Loss: 0.00010515287054646132, Train Acc: 0.9845582343943478
Test Loss: 0.10639571914306054, Test Acc: 0.872923951048951
Train Loss: 9.438544651299037e-05, Train Acc: 0.9845218151358438
Test Loss: 0.11268620503011283, Test Acc: 0.8812281468531469
Train Loss: 9.283905848931757e-05, Train Acc: 0.9854322965984412
Test Loss: 0.1119118087462612, Test Acc: 0.8825393356643356
Train Loss: 0.000104033928408789, Train Acc: 0.9836841721902542
Test Loss: 0.10798620531609009, Test Acc: 0.878277972027972
Train Loss: 8.762860616907066e-05, Train Acc: 0.985869327700488
Test Loss: 0.11663895297040056, Test Acc: 0.8759833916083916
Train Loss: 8.431876501987628e-05, Train Acc: 0.9861242625100153
Test Loss: 0.11408269208680083, Test Acc: 0.8774038461538461
Train Loss: 7.888971518963422e-05, Train Acc: 0.9866705513875738
Test Loss: 0.11339824862934493, Test Acc: 0.8713942307692307
Train Loss: 9.979844074979434e-05, Train Acc: 0.9841940418093088
Test Loss: 0.10488353762124385, Test Acc: 0.8835227272727273
Train Loss: 8.264269123340692e-05, Train Acc: 0.986597712870566
Test Loss: 0.11521465706450122, Test Acc: 0.8764204545454546
Train Loss: 8.051974607187754e-05, Train Acc: 0.9863791973195426
Test Loss: 0.115870549506345, Test Acc: 0.8829763986013986
Train Loss: 7.596318790549449e-05, Train Acc: 0.986561293612062
Test Loss: 0.12099308929555899, Test Acc: 0.8818837412587412
Train Loss: 8.534952966982123e-05, Train Acc: 0.9854687158569452
Test Loss: 0.11666288885932702, Test Acc: 0.8791520979020979
Train Loss: 9.145966305136485e-05, Train Acc: 0.9856143928909608
Test Loss: 0.113630469497684, Test Acc: 0.8833041958041958
Train Loss: 8.340059101977004e-05, Train Acc: 0.9863063588025348
Test Loss: 0.11781198560045315, Test Acc: 0.8793706293706294
Train Loss: 8.173056734058096e-05, Train Acc: 0.9855779736324568
Test Loss: 0.12477853387460712, Test Acc: 0.8846153846153846
Train Loss: 8.791585340969495e-05, Train Acc: 0.9861971010270231
Test Loss: 0.11762149306339817, Test Acc: 0.8752185314685315
Train Loss: 7.33795840446538e-05, Train Acc: 0.9869254861971011
Test Loss: 0.12063746453894601, Test Acc: 0.8835227272727273
Train Loss: 7.31515414321145e-05, Train Acc: 0.9866705513875738
Test Loss: 0.11535858520521568, Test Acc: 0.8789335664335665
Train Loss: 7.88989743340656e-05, Train Acc: 0.9861242625100153
Test Loss: 0.11930141446890531, Test Acc: 0.8747814685314685
Train Loss: 7.708856243368009e-05, Train Acc: 0.9867433899045815
Test Loss: 0.11903621921954038, Test Acc: 0.8771853146853147
Train Loss: 6.841101445322782e-05, Train Acc: 0.9873625172991478
Test Loss: 0.12381744247997974, Test Acc: 0.8816652097902098
Train Loss: 6.322840669200548e-05, Train Acc: 0.98728967878214
Test Loss: 0.1328172862034786, Test Acc: 0.8831949300699301
Train Loss: 9.049130116285523e-05, Train Acc: 0.9859421662174959
Test Loss: 0.1143687651525219, Test Acc: 0.8805725524475524
Train Loss: 7.950961057824084e-05, Train Acc: 0.9859057469589919
Test Loss: 0.12034393203529445, Test Acc: 0.8817744755244755
Train Loss: 8.497248194383514e-05, Train Acc: 0.9859785854759997
Test Loss: 0.11584489980152438, Test Acc: 0.8767482517482518
Train Loss: 6.746168024189489e-05, Train Acc: 0.9871075824896205
Test Loss: 0.12154805722770158, Test Acc: 0.8742351398601399
Train Loss: 7.209371713714523e-05, Train Acc: 0.9867433899045815
Test Loss: 0.12135580576747865, Test Acc: 0.8791520979020979
Train Loss: 6.0653628928494736e-05, Train Acc: 0.9879452254352101
Test Loss: 0.12936565804236627, Test Acc: 0.8798076923076923
BiLSTMModel(
  (lstm): LSTM(100, 256, bidirectional=True)
  (attention_weights_layer): Sequential(
    (0): Linear(in_features=256, out_features=256, bias=True)
    (1): ReLU(inplace=True)
  )
  (liner): Linear(in_features=256, out_features=11, bias=True)
  (act_func): Softmax(dim=1)
)
